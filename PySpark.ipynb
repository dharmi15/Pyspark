{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e428319d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\dharmi shah\\anaconda3\\lib\\site-packages (3.4.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\dharmi shah\\anaconda3\\lib\\site-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b294b4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b0c63f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "type(pd.read_csv('test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c49f315",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c328154",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('Dharmi').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a755e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-J30RHR5S:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Dharmi</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x27f03b6e530>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cea95fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=spark.read.csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09799cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=spark.read.option('header','true').csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33bca91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b888ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2bbaf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99071002",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('Dataframe').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25aec7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-J30RHR5S:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Dataframe</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x15de8f778e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac4ea909",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the dataset\n",
    "df_pyspark=spark.read.option('header','true').csv('test.csv',inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c6de581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Check schema\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7868e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+\n",
      "|   Name|Age|Experience|\n",
      "+-------+---+----------+\n",
      "| Dharmi| 24|        10|\n",
      "|  vinit| 26|         8|\n",
      "|   deep| 28|         5|\n",
      "|Vinayak| 29|         2|\n",
      "+-------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark=spark.read.csv('test.csv',header=True,inferSchema=True)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ea1df1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Check schema\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cc039e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fdf957a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='Dharmi', Age=24, Experience=10),\n",
       " Row(Name='vinit', Age=26, Experience=8),\n",
       " Row(Name='deep', Age=28, Experience=5),\n",
       " Row(Name='Vinayak', Age=29, Experience=2)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5fbf8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+\n",
      "|   Name|Age|Experience|\n",
      "+-------+---+----------+\n",
      "| Dharmi| 24|        10|\n",
      "|  vinit| 26|         8|\n",
      "|   deep| 28|         5|\n",
      "|Vinayak| 29|         2|\n",
      "+-------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee05357f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark.select('Name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4008f26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   Name|Age|\n",
      "+-------+---+\n",
      "| Dharmi| 24|\n",
      "|  vinit| 26|\n",
      "|   deep| 28|\n",
      "|Vinayak| 29|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select('Name','Age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5945f8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'Name'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24aa28bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'), ('Age', 'int'), ('Experience', 'int')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bc8ca50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----------------+----------+\n",
      "|summary|  Name|              Age|Experience|\n",
      "+-------+------+-----------------+----------+\n",
      "|  count|     4|                4|         4|\n",
      "|   mean|  null|            26.75|      6.25|\n",
      "| stddev|  null|2.217355782608345|       3.5|\n",
      "|    min|Dharmi|               24|         2|\n",
      "|    max| vinit|               29|        10|\n",
      "+-------+------+-----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73e8fd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Adding columns in dataframe\n",
    "df_pyspark=df_pyspark.withColumn('Experience After 2 years',df_pyspark['Experience']+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d3382f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------------------------+\n",
      "|   Name|Age|Experience|Experience After 2 years|\n",
      "+-------+---+----------+------------------------+\n",
      "| Dharmi| 24|        10|                      12|\n",
      "|  vinit| 26|         8|                      10|\n",
      "|   deep| 28|         5|                       7|\n",
      "|Vinayak| 29|         2|                       4|\n",
      "+-------+---+----------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb29e0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Droping the columns\n",
    "df_pyspark=df_pyspark.drop('Experience After 2 years')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "152958ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+\n",
      "|   Name|Age|Experience|\n",
      "+-------+---+----------+\n",
      "| Dharmi| 24|        10|\n",
      "|  vinit| 26|         8|\n",
      "|   deep| 28|         5|\n",
      "|Vinayak| 29|         2|\n",
      "+-------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b942c7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+\n",
      "|Newname|Age|Experience|\n",
      "+-------+---+----------+\n",
      "| Dharmi| 24|        10|\n",
      "|  vinit| 26|         8|\n",
      "|   deep| 28|         5|\n",
      "|Vinayak| 29|         2|\n",
      "+-------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Rename the columns\n",
    "df_pyspark.withColumnRenamed('Name','Newname').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ed9dab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('Practise').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "72fd44bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=spark.read.csv('test.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2bc3a69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+\n",
      "|   Name| Age|Experience|Salary|\n",
      "+-------+----+----------+------+\n",
      "| Dharmi|  24|        10| 30000|\n",
      "|  vinit|  26|         8| 25000|\n",
      "|   deep|  28|         5| 20000|\n",
      "|Vinayak|  29|         2| 40000|\n",
      "|   null|null|      null|  null|\n",
      "|   riya|null|         4|  null|\n",
      "|   null|null|      null|  2890|\n",
      "|   null|  31|      null|  null|\n",
      "+-------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "731f19ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+------+\n",
      "| Age|Experience|Salary|\n",
      "+----+----------+------+\n",
      "|  24|        10| 30000|\n",
      "|  26|         8| 25000|\n",
      "|  28|         5| 20000|\n",
      "|  29|         2| 40000|\n",
      "|null|      null|  null|\n",
      "|null|         4|  null|\n",
      "|null|      null|  2890|\n",
      "|  31|      null|  null|\n",
      "+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##dropping columns\n",
    "df_pyspark.drop('Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "70b23330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+\n",
      "|   Name| Age|Experience|Salary|\n",
      "+-------+----+----------+------+\n",
      "| Dharmi|  24|        10| 30000|\n",
      "|  vinit|  26|         8| 25000|\n",
      "|   deep|  28|         5| 20000|\n",
      "|Vinayak|  29|         2| 40000|\n",
      "|   null|null|      null|  null|\n",
      "|   riya|null|         4|  null|\n",
      "|   null|null|      null|  2890|\n",
      "|   null|  31|      null|  null|\n",
      "+-------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1ab047f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   Name|Age|Experience|Salary|\n",
      "+-------+---+----------+------+\n",
      "| Dharmi| 24|        10| 30000|\n",
      "|  vinit| 26|         8| 25000|\n",
      "|   deep| 28|         5| 20000|\n",
      "|Vinayak| 29|         2| 40000|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bf4d7af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   Name|Age|Experience|Salary|\n",
      "+-------+---+----------+------+\n",
      "| Dharmi| 24|        10| 30000|\n",
      "|  vinit| 26|         8| 25000|\n",
      "|   deep| 28|         5| 20000|\n",
      "|Vinayak| 29|         2| 40000|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##any=how\n",
    "df_pyspark.na.drop(how='any').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4312ebd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+\n",
      "|   Name| Age|Experience|Salary|\n",
      "+-------+----+----------+------+\n",
      "| Dharmi|  24|        10| 30000|\n",
      "|  vinit|  26|         8| 25000|\n",
      "|   deep|  28|         5| 20000|\n",
      "|Vinayak|  29|         2| 40000|\n",
      "|   riya|null|         4|  null|\n",
      "|   null|null|      null|  2890|\n",
      "|   null|  31|      null|  null|\n",
      "+-------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##threshold\n",
    "df_pyspark.na.drop(how='any',thresh=1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bbf9f9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   Name|Age|Experience|Salary|\n",
      "+-------+---+----------+------+\n",
      "| Dharmi| 24|        10| 30000|\n",
      "|  vinit| 26|         8| 25000|\n",
      "|   deep| 28|         5| 20000|\n",
      "|Vinayak| 29|         2| 40000|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how='any').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "66756bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   Name|Age|Experience|Salary|\n",
      "+-------+---+----------+------+\n",
      "| Dharmi| 24|        10| 30000|\n",
      "|  vinit| 26|         8| 25000|\n",
      "|   deep| 28|         5| 20000|\n",
      "|Vinayak| 29|         2| 40000|\n",
      "|   null| 31|      null|  null|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##subset\n",
    "df_pyspark.na.drop(how='any',subset=['age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dfc3db1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+----------+------+\n",
      "|          Name| Age|Experience|Salary|\n",
      "+--------------+----+----------+------+\n",
      "|        Dharmi|  24|        10| 30000|\n",
      "|         vinit|  26|         8| 25000|\n",
      "|          deep|  28|         5| 20000|\n",
      "|       Vinayak|  29|         2| 40000|\n",
      "|Missing Values|null|      null|  null|\n",
      "|          riya|null|         4|  null|\n",
      "|Missing Values|null|      null|  2890|\n",
      "|Missing Values|  31|      null|  null|\n",
      "+--------------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Filling the missing value\n",
    "df_pyspark.na.fill('Missing Values').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "576cedeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+\n",
      "|   Name| Age|Experience|Salary|\n",
      "+-------+----+----------+------+\n",
      "| Dharmi|  24|        10| 30000|\n",
      "|  vinit|  26|         8| 25000|\n",
      "|   deep|  28|         5| 20000|\n",
      "|Vinayak|  29|         2| 40000|\n",
      "|   null|null|      null|  null|\n",
      "|   riya|null|         4|  null|\n",
      "|   null|null|      null|  2890|\n",
      "|   null|  31|      null|  null|\n",
      "+-------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "227b081c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "imputer= Imputer(\n",
    "    inputCols=['Age','Experience','Salary'],\n",
    "    outputCols=[\"{}_imputed\".format(c) for c in ['Age','Experience','Salary']]\n",
    "    ).setStrategy(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "394c50dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+-----------+------------------+--------------+\n",
      "|   Name| Age|Experience|Salary|Age_imputed|Experience_imputed|Salary_imputed|\n",
      "+-------+----+----------+------+-----------+------------------+--------------+\n",
      "| Dharmi|  24|        10| 30000|         24|                10|         30000|\n",
      "|  vinit|  26|         8| 25000|         26|                 8|         25000|\n",
      "|   deep|  28|         5| 20000|         28|                 5|         20000|\n",
      "|Vinayak|  29|         2| 40000|         29|                 2|         40000|\n",
      "|   null|null|      null|  null|         27|                 5|         23578|\n",
      "|   riya|null|         4|  null|         27|                 4|         23578|\n",
      "|   null|null|      null|  2890|         27|                 5|          2890|\n",
      "|   null|  31|      null|  null|         31|                 5|         23578|\n",
      "+-------+----+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Add imputaions cols to df\n",
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dbc3bef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b3fbe0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('dataframe').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1903bf5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+\n",
      "|   Name| Age|Experience|Salary|\n",
      "+-------+----+----------+------+\n",
      "| Dharmi|  24|        10| 30000|\n",
      "|  vinit|  26|         8| 25000|\n",
      "|   deep|  28|         5| 20000|\n",
      "|Vinayak|  29|         2| 40000|\n",
      "|   null|null|      null|  null|\n",
      "|   riya|null|         4|  null|\n",
      "|   null|null|      null|  2890|\n",
      "|   null|  31|      null|  null|\n",
      "+-------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark=spark.read.csv('test.csv',header=True,inferSchema=True)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbdb29d",
   "metadata": {},
   "source": [
    "Filter operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e5f3f439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----------+------+\n",
      "|Name| Age|Experience|Salary|\n",
      "+----+----+----------+------+\n",
      "|deep|  28|         5| 20000|\n",
      "|null|null|      null|  2890|\n",
      "+----+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Salary of people less than 20000\n",
    "df_pyspark.filter(\"Salary<=20000\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "03ebb847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|Name| Age|\n",
      "+----+----+\n",
      "|deep|  28|\n",
      "|null|null|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(\"Salary<=20000\").select(['Name','Age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8b4363ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----------+------+\n",
      "|Name| Age|Experience|Salary|\n",
      "+----+----+----------+------+\n",
      "|deep|  28|         5| 20000|\n",
      "|null|null|      null|  2890|\n",
      "+----+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(df_pyspark['Salary']<=20000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "04591b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+------+\n",
      "|Name|Age|Experience|Salary|\n",
      "+----+---+----------+------+\n",
      "|deep| 28|         5| 20000|\n",
      "+----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter((df_pyspark['Salary']<=20000) &\n",
    "                  (df_pyspark['Salary']>=15000)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "86ce298d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   Name|Age|Experience|Salary|\n",
      "+-------+---+----------+------+\n",
      "| Dharmi| 24|        10| 30000|\n",
      "|  vinit| 26|         8| 25000|\n",
      "|Vinayak| 29|         2| 40000|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(~(df_pyspark['Salary']<=20000)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4c8d47",
   "metadata": {},
   "source": [
    "Pyspark Groupby and aggregrate Funcations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "423ad6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cd7f72a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('Agg').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c401ca00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-J30RHR5S:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Dataframe</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x15de8f778e0>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "90d19daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark=spark.read.csv('test.csv', header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "269f4a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+\n",
      "|   Name| Age|Experience|Salary|\n",
      "+-------+----+----------+------+\n",
      "| Dharmi|  24|        10| 30000|\n",
      "|  vinit|  26|         8| 25000|\n",
      "|   deep|  28|         5| 20000|\n",
      "|Vinayak|  29|         2| 40000|\n",
      "|   null|null|      null|  null|\n",
      "|   riya|null|         4|  null|\n",
      "|   null|null|      null|  2890|\n",
      "|   null|  31|      null|  null|\n",
      "+-------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "074bcfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4e9d9b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------------+-----------+\n",
      "|   Name|sum(Age)|sum(Experience)|sum(Salary)|\n",
      "+-------+--------+---------------+-----------+\n",
      "|   null|      31|           null|       2890|\n",
      "|  vinit|      26|              8|      25000|\n",
      "|Vinayak|      29|              2|      40000|\n",
      "| Dharmi|      24|             10|      30000|\n",
      "|   deep|      28|              5|      20000|\n",
      "|   riya|    null|              4|       null|\n",
      "+-------+--------+---------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Groupby\n",
    "df_pyspark.groupBy('Name').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "18b49c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------------+-----------+\n",
      "|Experience|sum(Age)|sum(Experience)|sum(Salary)|\n",
      "+----------+--------+---------------+-----------+\n",
      "|      null|      31|           null|       2890|\n",
      "|         5|      28|              5|      20000|\n",
      "|         4|    null|              4|       null|\n",
      "|         8|      26|              8|      25000|\n",
      "|        10|      24|             10|      30000|\n",
      "|         2|      29|              2|      40000|\n",
      "+----------+--------+---------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Group by experience which gives max salary\n",
    "df_pyspark.groupBy('Experience').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "64ec594a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------------+-----------+\n",
      "|Experience|avg(Age)|avg(Experience)|avg(Salary)|\n",
      "+----------+--------+---------------+-----------+\n",
      "|      null|    31.0|           null|     2890.0|\n",
      "|         5|    28.0|            5.0|    20000.0|\n",
      "|         4|    null|            4.0|       null|\n",
      "|         8|    26.0|            8.0|    25000.0|\n",
      "|        10|    24.0|           10.0|    30000.0|\n",
      "|         2|    29.0|            2.0|    40000.0|\n",
      "+----------+--------+---------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Experience').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "19f50c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|Experience|count|\n",
      "+----------+-----+\n",
      "|      null|    3|\n",
      "|         5|    1|\n",
      "|         4|    1|\n",
      "|         8|    1|\n",
      "|        10|    1|\n",
      "|         2|    1|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Experience').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c0fb2950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|sum(Salary)|\n",
      "+-----------+\n",
      "|     117890|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.agg({'Salary':'sum'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7944ffab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------------+-----------+\n",
      "|   Name|avg(Age)|avg(Experience)|avg(Salary)|\n",
      "+-------+--------+---------------+-----------+\n",
      "|   null|    31.0|           null|     2890.0|\n",
      "|  vinit|    26.0|            8.0|    25000.0|\n",
      "|Vinayak|    29.0|            2.0|    40000.0|\n",
      "| Dharmi|    24.0|           10.0|    30000.0|\n",
      "|   deep|    28.0|            5.0|    20000.0|\n",
      "|   riya|    null|            4.0|       null|\n",
      "+-------+--------+---------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('Name').avg().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f913d36b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
